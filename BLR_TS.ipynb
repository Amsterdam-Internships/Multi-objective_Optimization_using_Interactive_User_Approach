{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from gp_pref_elicit_luisa import dataset as data\n",
    "from gp_pref_elicit_luisa import gaussian_process as GP\n",
    "from momabs_bayesian import bayes_logistic as bayes_logistic\n",
    "from gp_pref_elicit_luisa.gp_utilities import utils_user as gp_utils_users\n",
    "from logistic_user import LogisticDecisionMaker as logistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing dataset class\n",
    "utils_comparisons = data.DatasetPairwise(num_objectives=2)\n",
    "GP = GP.GPPairwise(num_objectives=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic pareto coverage set\n",
    "synthetic_pcs = np.array([[0.14370116, 0.99159928],\n",
    "       [0.9797389 , 0.2242916 ],\n",
    "       [0.        , 1.        ],\n",
    "       [0.91055917, 0.45020785],\n",
    "       [0.59678925, 0.81854996],\n",
    "       [1.        , 0.        ],\n",
    "       [0.94198057, 0.352479  ],\n",
    "       [0.81501748, 0.65358114],\n",
    "       [0.99814566, 0.05429028],\n",
    "       [0.33305315, 0.94955291],\n",
    "       [0.28860669, 0.96123215],\n",
    "       [0.99999796, 0.02591092],\n",
    "       [0.98910769, 0.14092867],\n",
    "       [0.18584726, 0.98334638],\n",
    "       [0.05210043, 0.99838732],\n",
    "       [0.87761802, 0.52114756],\n",
    "       [0.74002719, 0.7144284 ],\n",
    "       [0.21487083, 0.97724899],\n",
    "       [0.43622937, 0.90230767],\n",
    "       [0.99525346, 0.08213535]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999796, 0.02591092],\n",
       "       [0.05210043, 0.99838732]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating random points from synthetic pcs \n",
    "start_points = synthetic_pcs[np.random.choice(synthetic_pcs.shape[0], size=2, replace=False)]\n",
    "start_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24067781, -1.43027198, -0.95858984,  0.42492366])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_simulation = logistic(no_obj=2, num_features=4)\n",
    "user_simulation.exact_compare(start_points[0], start_points[1])\n",
    "model_space = user_simulation.sample_model()\n",
    "model_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LogisticDecisionMaker.features() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m thompson_point \u001b[39m=\u001b[39m user_simulation\u001b[39m.\u001b[39;49mthompson_sampled_point(synthetic_pcs)\n\u001b[0;32m      2\u001b[0m thompson_point\n",
      "File \u001b[1;32md:\\modules\\thesis\\Multi-objective_Optimization_using_Interactive_User_Approach\\logistic_user.py:101\u001b[0m, in \u001b[0;36mLogisticDecisionMaker.thompson_sampled_point\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mthompson_sampled_point\u001b[39m(\u001b[39mself\u001b[39m, dataset):\n\u001b[1;32m--> 101\u001b[0m     dataset_features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m dataset]\n\u001b[0;32m    102\u001b[0m     w_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_model()\n\u001b[0;32m    103\u001b[0m     utilities \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39minner(w_sample, v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m dataset_features]\n",
      "File \u001b[1;32md:\\modules\\thesis\\Multi-objective_Optimization_using_Interactive_User_Approach\\logistic_user.py:101\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mthompson_sampled_point\u001b[39m(\u001b[39mself\u001b[39m, dataset):\n\u001b[1;32m--> 101\u001b[0m     dataset_features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m dataset]\n\u001b[0;32m    102\u001b[0m     w_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_model()\n\u001b[0;32m    103\u001b[0m     utilities \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39minner(w_sample, v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m dataset_features]\n",
      "\u001b[1;31mTypeError\u001b[0m: LogisticDecisionMaker.features() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "thompson_point = user_simulation.thompson_sampled_point(synthetic_pcs)\n",
    "thompson_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pref = gp_utils_users.UserPreference(num_objectives=2, std_noise=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watch out - trying to add comparison between same datapoints!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating ground truth utility function for the starting points\n",
    "ground_truth_utility_function_start = user_pref.get_preference(start_points, add_noise=True)\n",
    "# getting the index of the highest utility\n",
    "highest_utility_index_start = np.argmax(ground_truth_utility_function_start)\n",
    "# getting the index of the lowest utility\n",
    "lowest_utility_index_start = np.argmin(ground_truth_utility_function_start)\n",
    "# mapping the indices of the highest utility to the actual datapoint in the dataset\n",
    "highest_utility_point_dataset = start_points[highest_utility_index_start]\n",
    "# mapping the indices of the lowest utility to the actual datapoint in the dataset\n",
    "lowest_utility_point_dataset = start_points[lowest_utility_index_start]\n",
    "\n",
    "# adding the highest utility point, which is the winner, to the dataset \n",
    "utils_comparisons.add_single_comparison(highest_utility_point_dataset, lowest_utility_point_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_best = np.max(start_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(v):\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    for i in range(len(v)):\n",
    "        for v_j in v[i+1]:\n",
    "            mins.append(min(v[i], v_j))\n",
    "            maxs.append(max(v[i], v_j))\n",
    "    result = list(v) + maxs + mins\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m features(start_points)\n",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m, in \u001b[0;36mfeatures\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m      3\u001b[0m maxs \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(v)):\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mfor\u001b[39;00m v_j \u001b[39min\u001b[39;00m v[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[0;32m      6\u001b[0m         mins\u001b[39m.\u001b[39mappend(\u001b[39mmin\u001b[39m(v[i], v_j))\n\u001b[0;32m      7\u001b[0m         maxs\u001b[39m.\u001b[39mappend(\u001b[39mmax\u001b[39m(v[i], v_j))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "features(start_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0,1])\n",
    "wprior = GP.prior_mean(x=start_points)\n",
    "H = np.array([[0, 1],\n",
    "              [1, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X must be a N*p matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# bayesian logistic regression \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m bayes_logistic \u001b[39m=\u001b[39m bayes_logistic\u001b[39m.\u001b[39;49mfit_bayes_logistic(y\u001b[39m=\u001b[39;49my, X\u001b[39m=\u001b[39;49mstart_points, wprior\u001b[39m=\u001b[39;49mwprior, H\u001b[39m=\u001b[39;49mH, weights\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, solver\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mNewton-CG\u001b[39;49m\u001b[39m'\u001b[39;49m, bounds\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, maxiter\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[1;32md:\\modules\\thesis\\Multi-objective_Optimization_using_Interactive_User_Approach\\momabs_bayesian\\bayes_logistic.py:373\u001b[0m, in \u001b[0;36mfit_bayes_logistic\u001b[1;34m(y, X, wprior, H, weights, solver, bounds, maxiter)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39m# Check that dimensionality of inputs agrees\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[0;32m    371\u001b[0m \u001b[39m# check X\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(X\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mX must be a N*p matrix\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    374\u001b[0m (nX, pX) \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[0;32m    376\u001b[0m \u001b[39m# check y\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: X must be a N*p matrix"
     ]
    }
   ],
   "source": [
    "# bayesian logistic regression \n",
    "bayes_logistic = bayes_logistic.fit_bayes_logistic(y=y, X=start_points, wprior=wprior, H=H, weights=None, solver='Newton-CG', bounds=None, maxiter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0.14370116, 0.99159928]), 0.99159928, 0.14370116]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the feature vectors\n",
    "max_feature_vector = np.max(current_best, )\n",
    "min_feature_vector = np.min(current_best, )\n",
    "# combined_feature_vector = x -> 1st value vector, y -> 2nd value vector, max(x,y), min(x,y)\n",
    "# eg: [1,2] -> [1,2, max(1,2), min(1,2)] = [1, 2, 2, 1]\n",
    "# combined_feature_vector = [[current_best, , np.max(start_points), np.min(start_points)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate normal\n",
    "# multivariate_normal(mean=, cov=, allow_singular=False, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
